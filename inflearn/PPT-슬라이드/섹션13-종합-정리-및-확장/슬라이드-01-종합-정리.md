# 슬라이드 01: 종합 정리

## 슬라이드 내용 (한 장)

**tz-chatbot 흐름 요약**  
• **클라이언트** → chat-gateway(JWT·system_id) → **Dify**(앱·워크플로우·RAG 도구) → **RAG Backend** → Qdrant·MinIO  
• **RAG 문서**: MinIO 업로드 → Ingestion Job/CronJob(Loader·Splitter·Embedding) → Qdrant 컬렉션  
• **관리**: chat-admin(시스템 등록·채팅 조회·재색인). DB: chat_admin(PostgreSQL)

**설치·배포 순서**  
1. 인프라(bootstrap: K8s·Ingress NGINX·MinIO·cert-manager 등)  
2. RAG 스택(Qdrant·rag-backend·Ingestion·토픽별 분리)  
3. Dify 설치·앱·RAG 도구 URL  
4. chat_admin DB 생성·Secret  
5. chat-gateway·chat-admin 배포·Ingress·TLS  
6. 운영: 로깅·Pod 상태·모니터링·백업

---

## 발표 노트

강의에서 다룬 tz-chatbot 구조를 한 번 정리하면 이렇습니다. 클라이언트는 JWT와 system_id를 가지고 chat-gateway로 요청을 보냅니다. gateway는 해당 system_id의 Dify 앱과 API Key로 Dify를 호출하고, Dify 워크플로우에서 RAG 도구가 필요하면 RAG Backend를 부릅니다. RAG Backend는 Qdrant에서 벡터 검색하고, 원문은 MinIO 등에서 가져올 수 있습니다. RAG 문서는 MinIO에 올려 두고, Ingestion Job이나 CronJob이 Loader, Splitter, Embedding을 거쳐 Qdrant 컬렉션에 넣습니다. 관리 측면에서는 chat-admin으로 시스템 등록, 채팅 조회, 재색인 트리거를 하고, chat_admin PostgreSQL DB를 공유합니다.

설치와 배포 순서는 인프라를 bootstrap으로 올린 뒤, RAG 스택을 설치하고 토픽별로 분리하고, Dify를 설치해서 앱과 RAG 도구 URL을 잡고, chat_admin DB를 만들고 Secret을 넣은 다음 chat-gateway와 chat-admin을 배포하고 Ingress와 TLS를 걸고, 운영 단계에서는 로깅, Pod 상태 확인, 모니터링, 백업을 하시면 됩니다.
