# 슬라이드 05: 전체 데이터 플로우

## 슬라이드 내용 (한 장)

**채팅 한 번 보낼 때 (온라인)**  
1. 클라이언트 앱 → chat-gateway (/v1/chat 등, JWT 또는 API Key)  
2. chat-gateway → Dify (system_id에 따라 앱·API Key 선택)  
3. Dify → 필요 시 RAG Backend 도구 호출 (질의 전달)  
4. RAG Backend → Qdrant 유사 벡터 검색 → 청크 반환 → Dify  
5. Dify → LLM이 RAG 결과 참고해 답변 생성 → chat-gateway  
6. chat-gateway → DB 저장(설정에 따라), 클라이언트에 응답

**문서가 RAG에 반영될 때 (오프라인·배치)**  
1. 문서를 MinIO rag-docs/raw/{토픽}/ 에 업로드 (관리 화면 또는 직접)  
2. RAG Ingestion (Job/CronJob): MinIO 읽기 → LangChain Loader·Splitter·Embedding → Qdrant upsert  
3. 이후 사용자 질의 시 RAG Backend가 이 컬렉션에서 검색

**정리**: 온라인 = 클라이언트→gateway→Dify→(RAG Backend→Qdrant)→Dify→gateway→클라이언트 / 오프라인 = MinIO→Ingestion→Qdrant

---

## 발표 노트

전체 데이터 플로우를 온라인과 오프라인으로 나눠서 보겠습니다.

채팅을 한 번 보낼 때, 즉 온라인 플로우는 이렇습니다. 클라이언트 앱에서 chat-gateway로 메시지를 보냅니다. /v1/chat 같은 API를 쓰고, JWT나 API Key로 인증합니다. gateway는 system_id에 따라 어떤 Dify 앱을 쓸지, 어떤 API Key를 쓸지 정해서 Dify로 요청을 넘깁니다. Dify는 필요하면 RAG 도구를 호출하는데, 이때 RAG Backend URL로 질의를 보냅니다. RAG Backend는 Qdrant에서 유사 벡터 검색을 하고, 상위 청크를 가져와서 Dify에 돌려줍니다. Dify는 LLM이 이 RAG 결과를 참고해서 답변을 만들고, 그걸 다시 chat-gateway로 보냅니다. chat-gateway는 설정에 따라 DB에 대화를 저장하고, 최종 응답을 클라이언트에 돌려줍니다.

문서가 RAG에 반영되는 건 오프라인, 배치 단계입니다. 먼저 문서를 MinIO의 rag-docs 버킷 안 raw/cointutor, raw/drillquiz 같은 토픽별 경로에 업로드합니다. 관리 화면에서 올리거나 직접 올릴 수 있습니다. 그다음 RAG Ingestion이 Job이나 CronJob으로 돌아가면서 MinIO에서 읽고, LangChain으로 로드·분할·임베딩한 뒤 Qdrant에 upsert합니다. 이렇게 하면 이후 사용자 질의가 들어왔을 때 RAG Backend가 방금 넣은 컬렉션에서 검색하게 됩니다.

정리하면, 온라인은 클라이언트에서 gateway, Dify, 필요 시 RAG Backend와 Qdrant를 거쳐 다시 돌아오는 흐름이고, 오프라인은 MinIO에 문서를 두고 Ingestion으로 Qdrant에 넣는 흐름입니다. 이 두 가지를 구분해 두시면 나중에 디버깅이나 설계할 때 도움이 됩니다.
